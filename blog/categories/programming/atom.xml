<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">

  <title><![CDATA[Category: programming | ./home/davidsiaw]]></title>
  <link href="https://davidsiaw.github.io/blog/categories/programming/atom.xml" rel="self"/>
  <link href="https://davidsiaw.github.io/"/>
  <updated>2019-08-17T15:54:24+00:00</updated>
  <id>https://davidsiaw.github.io/</id>
  <author>
    <name><![CDATA[davidsiaw]]></name>
    
  </author>
  <generator uri="http://octopress.org/">Octopress</generator>

  
  <entry>
    <title type="html"><![CDATA[Working with mruby]]></title>
    <link href="https://davidsiaw.github.io/blog/2019/08/17/working-with-mruby/"/>
    <updated>2019-08-17T13:55:01+00:00</updated>
    <id>https://davidsiaw.github.io/blog/2019/08/17/working-with-mruby</id>
    <content type="html"><![CDATA[<p>Having worked with Lua before and made a <a href="https://github.com/davidsiaw/luacppinterface">LuaCppInterface</a>, I decided about a year ago to start working on a C++ interface for mounting mruby as a scripting language.</p>

<p>To start, I have been developing in Ruby for several years now and I found it to be quite a pleasant language to work with. The particularly attractive thing about Ruby is its ability to create very clean DSLs. I have proceeded to use this to build some <a href="https://github.com/davidsiaw/sumomo">DSLs of</a> <a href="https://github.com/davidsiaw/weaver">my own</a>.</p>

<p>Despite the power of Ruby, it turned out to be incredibly hard to use as scripting language. However, recently a Japanese-Government-funded project <a href="http://www.mruby.org/">mruby</a> has been taking off and has headed into version 2.0.1. A year ago when I tried using it it was in version 1.4.0, and it was already in a fairly stable state. Since its syntax is meant to be compatible with Ruby 1.9 and its easy to compile into a C++ project, I decided to try it out.</p>

<h2>mruby-cpp</h2>

<p>To that end, I created <a href="https://github.com/davidsiaw/mruby-cpp">mruby-cpp</a> which provides a C++ frontend into mruby. Its still in beta as I trawl through the mruby C API and slowly gain an understanding of it. I&rsquo;ll continue to evolve it until it makes sense in both the C++ and mruby contexts.</p>

<h3>Simple introduction</h3>

<p>To start, <a href="https://github.com/davidsiaw/mruby-cpp">mruby-cpp</a> is a header-only C++ library. Just clone it into your sources as a submodule or copy it in and start using it. Your executable obviously needs to be linked with <code>libmruby.a</code>.</p>

<p>You can run scripts like this:</p>

<pre><code class="cpp">#include &lt;mruby.hpp&gt;

int main()
{
    vm.run("puts 'hello ruby'");
    return 0;
}
</code></pre>

<p>You can also set and get global variables, instance variables and class variables:</p>

<pre><code class="cpp">vm.run("$a = 100;");
int global_a = vm.get_global_variable&lt;int&gt;("$a");

vm.run("@a = 100;");
int instance_a = vm.get_instance_variable&lt;int&gt;("@a");

vm.run("@@a = 100;");
int class_a = vm.get_class_variable&lt;int&gt;("@@a");
</code></pre>

<p>You can bind your C++ classes and their methods to mruby, and specify constructor arguments too!</p>

<pre><code class="cpp">class Person {
    int age;
public:
    Person(int age) : age(age) { }
    int how_old() const { return age; }
};

auto cls = vm.create_class&lt;Person&gt;("Person");
cls.bind_instance_method("how_old", &amp;Person::how_old);
vm.run("puts Person.new(5).how_old")
</code></pre>

<p>Hopefully you will have a good idea of what I plan to achieve with this library. There are more examples in the <a href="https://github.com/davidsiaw/mruby-cpp/tree/master/tests">tests folder</a>.</p>

<h3>See the tests for more examples!</h3>

<p>All the capabilities of <a href="https://github.com/davidsiaw/mruby-cpp">mruby-cpp</a> are tested by the <a href="https://github.com/davidsiaw/mruby-cpp/tree/master/tests">tests</a> which are also really good examples of how to use <a href="https://github.com/davidsiaw/mruby-cpp">mruby-cpp</a>.</p>

<h2>mruby</h2>

<p>While I was writing this library, I&rsquo;ve learned a few things about mruby and actually about Ruby itself too.</p>

<h3>The C API isn&rsquo;t well documented</h3>

<p>One of the first things I realize when I started looking for ways to do things in mruby is its C API is sparsely documented. There are a bunch of comments in the headers but they are not nearly detailed enough.</p>

<p>A lot of functions have very abbreviated names such as</p>

<pre><code class="c">mrb_value mrb_vm_special_get(mrb_state*, mrb_sym);
void mrb_vm_special_set(mrb_state*, mrb_sym, mrb_value);
mrb_value mrb_vm_cv_get(mrb_state*, mrb_sym);
void mrb_vm_cv_set(mrb_state*, mrb_sym, mrb_value);
mrb_value mrb_vm_const_get(mrb_state*, mrb_sym);
void mrb_vm_const_set(mrb_state*, mrb_sym, mrb_value);
</code></pre>

<p>I still don&rsquo;t know what <code>mrb_vm_special_get</code> mean, but I know <code>cv</code> means class variable and <code>const</code> means constant. These are the <code>vm</code> variations, which means they only access global scope. Strangely enough, matz removed <code>vm</code> variations for the instance variables. Not sure why that is the case.</p>

<p>Sometimes typenames are confusing and its not entirely clear how some types are converted to other types, such as <code>RProc*</code> and <code>mrb_value</code>.</p>

<h3>Difficulties I faced</h3>

<p>While writing mruby-cpp, I encountered some difficulty with unifying mruby objects. All things in mruby are objects but they are not treated that way in the API. This is something I still have to solve.</p>

<p>Contrast with Lua where it exposes its GC reference api allowing you to increment and decrement references to its objects, and allowing you to create your own objects on the Lua GC and reference them the same way. This means that you can basically have a variant of the <code>shared_pointer</code> but managed by the Lua GC.</p>

<p>In mruby when you create a function you are forced to assign it to a class with a name. However, you can create a <code>proc</code> but it has a transparent <code>self</code> keyword, which means its impossible to associate it to an object.</p>

<p>As a result, the easiest way to work with mruby-cpp right now is to create classes and bind functions to them so you can use them in mruby. It makes little to no sense creating a function and assigning it to a variable. I am still working on a nice way to do this, and I spent hours trying to find a way to pass a function to mruby as a callable object.</p>

<p>The differences between procs, objects, classes and modules also mean that it was difficult to create an <code>mruby::Object</code> class. Meaning, pure ruby objects cannot really be passed to C++ with mruby-cpp right now.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Jepsen and Docker]]></title>
    <link href="https://davidsiaw.github.io/blog/2018/08/16/jepsen-and-docker/"/>
    <updated>2018-08-16T00:06:00+00:00</updated>
    <id>https://davidsiaw.github.io/blog/2018/08/16/jepsen-and-docker</id>
    <content type="html"><![CDATA[<p>Recently I have been reading a series of very interesting posts by an Aphyr who <a href="https://aphyr.com/tags/jepsen">tests distributed databases</a> and then publishes their performance under <a href="https://aphyr.com/posts/288-the-network-is-reliable">network partition</a> conditions, clock skews, dead nodes and other interesting failure conditions.</p>

<p>The tool he uses is called <a href="https://github.com/jepsen-io/jepsen">Jepsen</a> which he wrote himself, and the repo itself includes the set of tests that he used on various databases. After reading all the posts about how various supposedly industry-standard (I guess this is the industry standard) databases which claim to be quite reliable fail under precisely the conditions they are not supposed to fail under, I decided to try the tool out myself and document the experience.</p>

<p>My first thought about this tool was that it would be a great application of Docker, and it turns out he had already written a <a href="https://github.com/jepsen-io/jepsen/tree/master/docker">Docker harness for Jepsen</a>. This was great since you could do all sorts of things in the container environment of Docker and still simulate network partitions and all those nasty things without needing too much hardware.</p>

<p>I checked out Jepsen and ran the scripts the way it told me to.</p>

<pre><code class="ruby">$ sh up.sh
[INFO] Generating key pair
Generating public/private rsa key pair.
Your identification has been saved in ./secret/id_rsa.
.
.
.
</code></pre>

<p>And then it goes off and builds a bunch of containers from scratch.</p>

<p><img src="/images/blogimages/notlike.png" alt="Alt text" /></p>

<p>Then at the very end (after maybe 15 mins of downloading and installing) it goes</p>

<pre><code class="bash">.
.
.
jepsen-control | Please run `docker exec -it jepsen-control bash` in another terminal to proceed.
</code></pre>

<p>Excellent I can run it now!</p>

<p>So I open another terminal and type it in and instantly I&rsquo;m transported to where I should be to start working with Jepsen. Hooray!</p>

<pre><code class="bash">$ docker exec -it jepsen-control bash
Welcome to Jepsen on Docker
===========================

This container runs the Jepsen tests in sub-containers.

You are currently in the base dir of the git repo for Jepsen.
If you modify the core jepsen library make sure you "lein install" it so other tests can access.

To run a test:
   cd etcd &amp;&amp; lein run test --concurrency 10
root@control:/jepsen# 
</code></pre>

<p>Let&rsquo;s try the next command. It looks to me like I should try running the test on etcd with 10 clients?</p>

<pre><code class="bash"># cd etcd &amp;&amp; lein run test --concurrency 10
</code></pre>

<p>It then goes off and spews a large amount of output</p>

<pre><code class="bash">16:09:00.452 [main] INFO  jepsen.cli - Test options:
 {:concurrency 10,
 :test-count 1,
 :time-limit 60,
 :nodes ["n1" "n2" "n3" "n4" "n5"],
 :ssh
 {:username "root",
  :password "root",
  :strict-host-key-checking false,
  :private-key-path nil}}
.
.
.
</code></pre>

<p>It basically goes off and does a large number of reads and writes. At the very end, it comes back with this:</p>

<pre><code class="bash">Analysis invalid! (ﾉಥ益ಥ）ﾉ ┻━┻
</code></pre>

<p>Wow that was quick. I did not expect to run into an etcd problem so fast. I did not even specify any failures.</p>

<p>Seems like I had some code to read. After fumbling around I discovered the <a href="https://github.com/jepsen-io/jepsen/blob/master/etcd/src/jepsen/etcd.clj#L159">source file</a>.</p>

<p>Aha.</p>

<pre><code class="clojure">...
(merge tests/noop-test
         {:name "etcd"
          :os debian/os
          :db (db "v3.1.5")
          :client (client nil)
          :nemesis (nemesis/partition-random-halves)
          :model  (model/cas-register)
...
</code></pre>

<p>Looks like the Jepsen nemesis was baked into the test script. Well thats fine for now.</p>

<h2>Knossos</h2>

<p>The next step basically to me was to find out what was wrong. There was a large amount of data output so there must be a tool of some sort that can tell me what was wrong. (Or so I imagined)</p>

<p>After a bit of googling I came across another project called <a href="https://github.com/jepsen-io/knossos">Knossos</a>.</p>

<p>I didn&rsquo;t know very much about Clojure so I just followed through the README anyway. So first I cloned knossos</p>

<pre><code class="bash"># git clone https://github.com/jepsen-io/knossos
# cd knossos
</code></pre>

<p>I dug around to find the .edn file from my Jepsen run and discovered it in /jepsen/etcd/store/latest/history.edn</p>

<p>Then I ran the command in the README</p>

<pre><code class="bash"># lein run --model cas-register /jepsen/etcd/store/latest/history.edn 
/jepsen/etcd/store/latest/history.edn   false
</code></pre>

<p>Excellent. Yes. I knew that.</p>

<p>Scrolling down a little in the README I discovered it could generate the linearizability graph too. That was cool so I tried, by following the code in the README</p>

<pre><code class="bash">root@control:/knossos# lein repl
nREPL server started on port 37400 on host 127.0.0.1 - nrepl://127.0.0.1:37400
REPL-y 0.3.7, nREPL 0.2.12
Clojure 1.8.0
OpenJDK 64-Bit Server VM 1.8.0_181-8u181-b13-0ubuntu0.16.04.1-b13
    Docs: (doc function-name-here)
          (find-doc "part-of-name-here")
  Source: (source function-name-here)
 Javadoc: (javadoc java-object-or-class-here)
    Exit: Control+D or (exit) or (quit)
 Results: Stored in vars *1, *2, *3, an exception in *e
</code></pre>

<p>I am then dropped into the Clojure prompt, where I try clumsily to guess how things are done:</p>

<pre><code class="clojure">knossos.cli=&gt; (def h (read-history "/jepsen/etcd/store/latest/history.edn"))
#'knossos.cli/h
knossos.cli=&gt; (def a (competition/analysis (model/cas-register) h))
#'knossos.cli/a
knossos.cli=&gt; (require '[knossos.linear.report :as report])
nil
knossos.cli=&gt; (report/render-analysis! h a "linear.svg")
AssertionError Assert failed: No invocation for op {:process 2, :type :ok, :f :read, :value [0 4], :index 12, :time 421990474}
inv  knossos.linear.report/time-coords/fn--5143 (report.clj:186)
</code></pre>

<p>Okay, I had no idea what that meant. Looks like there are still kinks.</p>

<h2>Thoughts</h2>

<p>In short I have a few thoughts:</p>

<ol>
<li>Using docker for this is way cool</li>
<li>The analysis tool sucks</li>
<li>This can be so much more general</li>
</ol>


<h3>Using docker is way cool</h3>

<p>While Aphyr says that he uses his own LXC stuff to work with, I think its cool that he does provide a Docker interface. However he isn&rsquo;t taking advantage of a few things docker can do:</p>

<ol type="a">
<li>Prebuilt docker containers</li>
<li>Networking in docker that can be used to simulate faults</li>
<li>Skewing clocks in the container</li>
<li>Adding and removing new containers, simulating scaling effects and changing configuration</li>
</ol>


<p>It is probably because the tool is in its early stages of development, and really he knows how to use it the best, so he can do his stuff the best. But I can&rsquo;t help but feel he himself would benefit from some improvement in this domain. Perhaps he does not use it right now, or maybe he does in another way. I&rsquo;ve only sat with this code for the last 4 hours.</p>

<h3>The analysis tool sucks</h3>

<p>It needs to recover from weird errors nicely and maybe still present some amount of information. Unfortunately it doesn&rsquo;t, so I will need to spend some time figuring out what I did wrong. Once I get it then I will be able to truly start analysing databases myself.</p>

<h3>This can be so much more general</h3>

<p>All in all it looks like a large amount of the code done here is still quite research quality and tests, while composable seemed like they had to be baked into the testing code still. On the surface it felt to me that skew clocks, network failures, network delays and failing environments were things that did not have to be part of the test and could be external.</p>

<p><strong> None of this makes any of Jepsen less cool </strong></p>

<p>In my opinion all one should really need to do is specify what to do in order to perform a read, write or CAS, and the testing tool should attempt a combination of the three to figure out how a database puts up with it.</p>

<p>Its also likely to be the case because different databases are different. Some are queues, some are data structures, some are RDBMS and some are key value stores. However they all should have the same idea that storing data stores, and automated analysis that shows if it is CP or AP and how would be incredible. This is something I might work on in a later post when I have time.</p>

<h2>Conclusions</h2>

<p>The world needs more of these. This run was an eye-opener to real simulations of faults, and also the idea that distributed databases are actually extremely hard to understand and build. It also has shown me how one person who makes an effort to do something advanced and difficult and documents it in a clear manner can so quickly change the landscape of a field.</p>

<p>Thanks to him I am sure I and a large number of people now understand the definitions and jargon behind distributed databases which have been hidden behind walls of text in white papers and difficult to read (read longwinded) articles, and this really opens the door to helping people build better and more resilient systems.</p>

<p>This probably will not be the last post on distributed databases on the blog as I, as are many others, interested in how things can scale safely. We have more or less solved it for webservers, but scaling databases, that is clearly a different beast.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Script for setting up FTP to a folder on a Mac]]></title>
    <link href="https://davidsiaw.github.io/blog/2015/01/23/script-for-setting-up-ftp-to-a-folder-on-a-mac/"/>
    <updated>2015-01-23T10:34:00+00:00</updated>
    <id>https://davidsiaw.github.io/blog/2015/01/23/script-for-setting-up-ftp-to-a-folder-on-a-mac</id>
    <content type="html"><![CDATA[<p>This script came in handy many times when I had to share things with my other laptops or windows users.</p>

<p>On a Mac you should have Ruby installed. Macs normally come with an ftpd whose frontend has been ripped out, so you can only do this on the command line. Basically, write this to a script file (lets call it <code>setftp</code>)</p>

<p>and then use it by typing:</p>

<p><code>./setftp /directoryIWantToShare</code></p>

<p>Tested on Mavericks</p>

<pre><code class="ruby">#!/usr/bin/env ruby

#puts ARGV.inspect

puts `sudo -s launchctl unload -w /System/Library/LaunchDaemons/ftp.plist`

config = &lt;&lt;-THEFILE
# Set the ftp root dir to this folder
umask all 022
chroot GUEST #{ARGV[0]}
modify guest off
umask  guest 0707
upload guest on
THEFILE

File.open("/etc/ftpd.conf", 'w') { |file| file.write(config) }

puts `sudo -s launchctl load -w /System/Library/LaunchDaemons/ftp.plist`
</code></pre>

<p>With this you will have an ftpd turn on whose root folder is the folder you named. in this case it is <code>/directoryIWantToShare</code></p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Using Travis to deploy my blog]]></title>
    <link href="https://davidsiaw.github.io/blog/2014/10/30/using-travis-to-deploy-my-blog/"/>
    <updated>2014-10-30T01:07:00+00:00</updated>
    <id>https://davidsiaw.github.io/blog/2014/10/30/using-travis-to-deploy-my-blog</id>
    <content type="html"><![CDATA[<p>I&rsquo;ve been using Travis-CI more and more as a platform from which I can deploy things, due to the fact that we can run any code on it. Today I made it so that this blog is deployed to gh-pages when pushed. I have also set up my personal blog to be pushed this way as well.</p>

<p>Why did I use Travis-CI instead of Shippable or other CI systems for this? Well, its mainly due to the fact that I was already using Travis, and the tools (specifically the Travis gem) are quite mature. Many of the things that are quite troublesome, like generating a key and placing decrypt commands into the .travis.yml, are now covered in simple command line instructions.</p>

<p>My blog uses Jekyll + Octopress, but I don&rsquo;t like the limitations imposed by github on the templates I can use. So I decided it was better to simply upload the finished product. First of all, I push all my blog sources up to a public repository at <a href="https://github.com/davidsiaw/davidsiaw.github.io.source">https://github.com/davidsiaw/davidsiaw.github.io.source</a></p>

<p>While the setup is easy, its not obvious that you can do this. Hopefully this will go some way to helping others who want to circumvent the github limitations on their gh-pages content as well.</p>

<p>In this post I will show you how to set it up. First of all, I create a key that will give push access to my blog&rsquo;s repository at <a href="https://github.com/davidsiaw/davidsiaw.github.io">https://github.com/davidsiaw/davidsiaw.github.io</a> by calling up <code>ssh-keygen</code></p>

<pre><code class="">nagatsuki david$ ssh-keygen
Generating public/private rsa key pair.
Enter file in which to save the key (/Users/david/.ssh/id_rsa): deploy_key
Enter passphrase (empty for no passphrase): 
Enter same passphrase again: 
Your identification has been saved in deploy_key.
Your public key has been saved in deploy_key.pub.
The key fingerprint is:
89:8d:a9:60:5c:8b:77:05:c4:2b:05:a4:96:64:8e:fa david@nagatsuki
The key's randomart image is:
+--[ RSA 2048]----+
|     .=+o        |
|     *  o.       |
|    = o. o.      |
| o = ..=.o       |
|  = . =.S        |
|   o o .         |
|    E            |
|                 |
|                 |
+-----------------+
</code></pre>

<p>I then place the deploy_key.pub in my github repository.</p>

<p>Next, I make use of the Travis gem to encrypt my private key. I add the <code>--add</code> parameter to make it write to my .travis.yml (I am in the directory.)</p>

<pre><code>nagatsuki david$ travis encrypt-file deploy_key --add
encrypting deploy_key for davidsiaw/davidsiaw.github.io
storing result as deploy_key.enc
storing secure env variables for decryption

Make sure to add deploy_key.enc to the git repository.
Make sure not to add deploy_key to the git repository.
Commit all changes to your .travis.yml.
</code></pre>

<p>This gives me a deploy_key.enc that is my encrypted private key.</p>

<p>In order to use this key, I need to add some more lines to <a href="https://github.com/davidsiaw/davidsiaw.github.io.source/blob/master/.travis.yml">.travis.yml</a> to enable it to push to github. First of all, I need to install the key into the .ssh folder so git can use it. I also chmod it so ssh will not complain.</p>

<pre><code class="yml">- chmod 600 deploy-key
- cp deploy-key ~/.ssh/id_rsa
</code></pre>

<p>With this, I can now tell Travis to push the generated files. All I do is tell it to generate the site (since this is just Jekyll), and then call my <a href="https://github.com/davidsiaw/davidsiaw.github.io.source/blob/master/deploy">deploy script</a> which simply pushes the right stuff up to github.</p>

<pre><code>- bundle exec rake generate
- bash deploy
</code></pre>

<p>With this, my website gets updated everytime I push my changes to <a href="https://github.com/davidsiaw/davidsiaw.github.io.source">https://github.com/davidsiaw/davidsiaw.github.io.source</a>, Travis will automatically update my blog.</p>
]]></content>
  </entry>
  
  <entry>
    <title type="html"><![CDATA[Online vs Batch learning]]></title>
    <link href="https://davidsiaw.github.io/blog/2013/03/18/online-vs-batch-learning/"/>
    <updated>2013-03-18T00:00:00+00:00</updated>
    <id>https://davidsiaw.github.io/blog/2013/03/18/online-vs-batch-learning</id>
    <content type="html"><![CDATA[<p>While debugging neuron, my new neural network simulation application, I found some (visually) interesting differences between online and batch learning. While batch learning is usually touted as a better form of learning, I found that the two don&rsquo;t seem to make much difference, except for a steppy curve from online learning, as I would expect as the gradient changes differently if you keep calculating the values in a cycle instead of calculating the combined gradient of all the training data.</p>

<p>Here are the results from training a 2-2-1 network with biases with XOR as training data:</p>

<p><a href="http://labs.astrobunny.net/wp-content/uploads/2013/03/wpid-neuron2.jpg" rel="lightbox"><img src="http://labs.astrobunny.net/wp-content/uploads/2013/03/wpid-neuron2-500x81.jpg" alt="" title="Picture" width="500" height="81" class="alignnone size-medium wp-image-1204" /></a></p>

<p>with the weights initialized to:</p>

<p>double[] wx0 = { 0.1, 0.2 };
double[] wx1 = { 0.3, 0.4 };
double[] wx2 = { 0.5, 0.6 };</p>

<p>double wh0 = 0.7;
double wh1 = 0.9;
double wh2 = 1.1;</p>

<p>Where wx are the values between the input and hidden layer and wh are the values between the hidden and output layer.</p>

<p>Here is the network topography:</p>

<p><a href="http://labs.astrobunny.net/wp-content/uploads/2013/03/wpid-neuron1.jpg" rel="lightbox"><img src="http://labs.astrobunny.net/wp-content/uploads/2013/03/wpid-neuron1-500x361.jpg" alt="" title="Picture" width="500" height="361" class="alignnone size-medium wp-image-1204" /></a></p>

<p>Here is the training error:</p>

<p><a href="http://labs.astrobunny.net/wp-content/uploads/2013/03/wpid-chart_1-1.png" rel="lightbox"><img src="http://labs.astrobunny.net/wp-content/uploads/2013/03/wpid-chart_1-1-500x272.png" alt="" title="Picture" width="500" height="272" class="alignnone size-medium wp-image-1204" /></a></p>
]]></content>
  </entry>
  
</feed>
